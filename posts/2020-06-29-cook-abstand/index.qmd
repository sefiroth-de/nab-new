---
title: "Cook Abstand"
author: "Norman Markgraf"
date: '2020-06-29'
lang: de-DE
date-modified: last-modified
word-count: true
reading-time: true
categories: 
  - Statistik
---

```{r setup, echo=FALSE, include=FALSE, warning=FALSE}
library(mosaic)

set.seed(2009)
```

**Frage: Was macht einen Wert zum Ausreißer?**

Eine mögliche Antwort lautet:
_Ein Wert gilt als Ausreißer, wenn er deutlich von den übrigen Werten abweicht **und** einen (starken) Einfluss auf das Modell ausübt._

Ein Verfahren zur Identifikation solcher Ausreißer ist der **Cook-Abstand** (engl.: **Cook's distance**). 
Die zugrunde liegende Idee besteht darin zu messen, wie stark ein einzelner Wert das Modell beeinflusst. 
Dazu vergleicht man das Modell einmal mit und einmal ohne diesen Wert.

Sehen wir uns den Cook-Abstand anhand eines einfachen linearen Regressionsmodells näher an:


### Vorbereitungen

Wir nutzen das Paket `mosaic`, daher laden wir es zunächst:

```{r}
library(mosaic)
```

Falls die **tipping**-Daten nicht lokal vorliegen, werden sie aus dem Internet geladen:

```{r tipping_daten_ggf_herunterladen}
if (!file.exists("tips.csv")) {
  download.file("https://goo.gl/whKjnl", destfile = "tips.csv")
}
```

Nun werden die Daten eingelesen:

```{r tipping_daten_in_de_speicher_laden}
tips <- read.csv2("tips.csv")
```

Für unser Modell verwenden wir nur die Variablen `total_bill` und `tip`:

```{r tippings_daten_kürzen}
tips %>% select(c("total_bill", "tip")) -> tips
```

## Unser Modell:

Zuerst ein Streudiagramm zur Visualisierung der Daten:

```{r}
gf_point(tip ~ total_bill, data = tips)
```

Dann erstellen wir ein lineares Regressionsmodell:

```{r}
erg_lm <- lm(tip ~ total_bill, data = tips)
summary(erg_lm)
```

Visualisierung der Regressionsgeraden:

```{r, warning=FALSE}
gf_point(tip ~ total_bill, data = tips) %>%
  gf_coefline(
    model = erg_lm,
    color = ~ "Regressionsgerade",
    show.legend = FALSE
  ) 
```

Einflussreiche Ausreißer können bei linearen Modellen problematisch sein. Was passiert, wenn wir einen potenziellen Ausreißer entfernen?

Beispiel: Wir eliminieren die Beobachtung mit dem Index 173

```{r}
tips %>% slice(173) -> tips_removed
tips_removed
```

```{r}
tips %>% slice(-173) -> tips_red
erg_lm_red <- lm(tip ~ total_bill, data = tips_red)
summary(erg_lm_red)
```

Grafischer Vergleich:

```{r}
gf_point(tip ~ total_bill, data = tips_red) %>%
  gf_coefline(
    model = erg_lm,
    color = ~ "Regressionsgerade"
    ) %>%
  gf_point(
    tip ~ total_bill, 
    colour = ~ "Entfernter Punkt",
    data = tips_removed)
```

## Berechnung des Cook-Abstands

Wir vergleichen die Prognosen beider Modelle:

```{r}
new_data <- tibble(total_bill = tips$total_bill)
prognose_lm <- predict(erg_lm, newdata = new_data)
prognose_lm_red <- predict(erg_lm_red, newdata = new_data)
```

Berechnung:

$$
d_j = \sum_{i=1}^n \left(\hat{y}_i - \hat{y}_{i(j)}\right)^2
$$ 
Dabei ist $\hat{y}_i$ die Prognose des Wertes $y_i$ auf Basis von $x_i$ mit dem Originalmodell und $\hat{y}_{i(j)}$ die Prognose wenn man die $j$-te Beobachtung aus dem Modell gestrichen hat.

```{r d_j_berechnen}
d_j <- sum((prognose_lm - prognose_lm_red)^2)
d_j
```

Der Cook Abstand $D_j$ wird nun noch *normiert* durch $${\text{var}_{\text{cook}}} = p \cdot s_{\epsilon_i^2}^2$$ Dabei ist $s_{\epsilon_i^2}^2$ der erwartungstreue Schätzer der Varianz der Residuen und $p$ die Anzahl aller erklärenden Variablen plus Eins, also: \$ 1 + 1 = 2\$.

Normierung des Cook-Abstands:

$$
  D_j = \frac{d_j}{\text{var}_{\text{cook}}} = \frac{\sum\limits_{i=1}^n \left(\hat{y}_i - \hat{y}_{i(j)}\right)^2}{p \cdot s_{\epsilon_i^2}^2}
$$


```{r}
# Summary des Modells
selm <- summary(erg_lm)

# Wir finden p als rank im Modell
p <- erg_lm$rank 

# Wir finden den erwatungtreuen Schätzer im Summary des Modells
s_quad_eps_quad <- (selm$sigma)^2 

var_cook = p * s_quad_eps_quad

D_j = d_j / var_cook
D_j
```

Alternativ kann der Wert direkt mit cooks.distance() berechnet werden:

```{r}
cooks.distance(erg_lm)[173]
```

Wann aber ist nun ein Wert ein *einflussreicher* Ausreißer?

## Entscheidungskriterien

Cook selber gibt dafür die Bedingung $D_j > 1$ an. Andere Autor\*innen schreiben $D_j > 4/n$, wobei $n$ die Anzahl der Beobachtung ist.

In unserem Beispiel liefert die Variante $D_j > 1$

```{r}
cooks <- cooks.distance(erg_lm)
names(cooks) <- NULL
n <- nrow(tips)

any(cooks > 1)
```

keinen Ausreißer.

Wenn wir jedoch mit $D_j > 4/n$ suchen .

```{r}
any(cooks > 4/n)
```

dann gibt es Ausreißer.

Die Indices dieser finden wir mit:

```{r}
which(cooks > 4/n)
```

Daten bereinigen:

```{r}
remove <- which(cooks > 4/n)
tips %>% slice(-remove) -> tips_no_outliers
tips %>% slice(remove) -> tips_removed
erg_lm_no_outliers <- lm(tip ~ total_bill, data = tips_no_outliers)
```

Ergebnis des Modells:

```{r}
summary(erg_lm_no_outliers)
```
Daten bereinigen:

```{r}
gf_point(tip ~ total_bill, data = erg_lm_no_outliers) %>%
  gf_coefline(
    model = erg_lm_no_outliers, 
    color = ~"Regressionsgerade"
  )
```

Grafischer Vergleich beider Modelle:

```{r}
gf_point(tip ~ total_bill, data = erg_lm) %>%
  gf_coefline(
    model =  erg_lm,
    color = ~ "Regressionsgerade (Orginal)"
  ) %>%
  gf_coefline(
    model = erg_lm_no_outliers,
    color = ~ "Regressionsgerade (No Outliers)"
  ) %>%
  gf_point(
    tip ~ total_bill,
    color = ~ "Entfernte Punkte",
    data = tips_removed
  )
```

## Modelle in Gleichungsform

Das ursprüngliche Modell: 

$$
  \widehat{tips}_{lm} = `r coef(erg_lm)[1]` + `r coef(erg_lm)[2]` \cdot total\_bill
$$

Das um pot. Ausreißer bereinigte Modell: 

$$
  \widehat{tips}_{lm\_no} `r coef(erg_lm_no_outliers)[1]` + `r coef(erg_lm_no_outliers)[2]` \cdot total\_bill
$$
